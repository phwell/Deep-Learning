{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricar\\AppData\\Roaming\\Python\\Python37\\site-packages\\requests\\__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.9) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "C:\\Users\\ricar\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ricar\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ricar\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ricar\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ricar\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ricar\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0188 - mean_absolute_error: 0.1043\n",
      "Epoch 00001: loss improved from inf to 0.01883, saving model to pesos.h5\n",
      "36/36 [==============================] - 7s 191ms/step - loss: 0.0188 - mean_absolute_error: 0.1043\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0051 - mean_absolute_error: 0.0559\n",
      "Epoch 00002: loss improved from 0.01883 to 0.00510, saving model to pesos.h5\n",
      "36/36 [==============================] - 7s 186ms/step - loss: 0.0051 - mean_absolute_error: 0.0559\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0048 - mean_absolute_error: 0.0549\n",
      "Epoch 00003: loss improved from 0.00510 to 0.00483, saving model to pesos.h5\n",
      "36/36 [==============================] - 7s 181ms/step - loss: 0.0048 - mean_absolute_error: 0.0549\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0039 - mean_absolute_error: 0.0482\n",
      "Epoch 00004: loss improved from 0.00483 to 0.00386, saving model to pesos.h5\n",
      "36/36 [==============================] - 7s 184ms/step - loss: 0.0039 - mean_absolute_error: 0.0482\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0038 - mean_absolute_error: 0.0473\n",
      "Epoch 00005: loss improved from 0.00386 to 0.00376, saving model to pesos.h5\n",
      "36/36 [==============================] - 7s 184ms/step - loss: 0.0038 - mean_absolute_error: 0.0473\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0036 - mean_absolute_error: 0.0468\n",
      "Epoch 00006: loss improved from 0.00376 to 0.00358, saving model to pesos.h5\n",
      "36/36 [==============================] - 6s 179ms/step - loss: 0.0036 - mean_absolute_error: 0.0468\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0032 - mean_absolute_error: 0.0435\n",
      "Epoch 00007: loss improved from 0.00358 to 0.00321, saving model to pesos.h5\n",
      "36/36 [==============================] - 7s 184ms/step - loss: 0.0032 - mean_absolute_error: 0.0435\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0029 - mean_absolute_error: 0.0414\n",
      "Epoch 00008: loss improved from 0.00321 to 0.00292, saving model to pesos.h5\n",
      "36/36 [==============================] - 6s 178ms/step - loss: 0.0029 - mean_absolute_error: 0.0414\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0031 - mean_absolute_error: 0.0428\n",
      "Epoch 00009: loss did not improve from 0.00292\n",
      "36/36 [==============================] - 6s 171ms/step - loss: 0.0031 - mean_absolute_error: 0.0428\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0028 - mean_absolute_error: 0.0409\n",
      "Epoch 00010: loss improved from 0.00292 to 0.00281, saving model to pesos.h5\n",
      "36/36 [==============================] - 6s 178ms/step - loss: 0.0028 - mean_absolute_error: 0.0409\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0025 - mean_absolute_error: 0.0379- ETA: 3s - loss: 0.0026 - mean_\n",
      "Epoch 00011: loss improved from 0.00281 to 0.00247, saving model to pesos.h5\n",
      "36/36 [==============================] - 7s 196ms/step - loss: 0.0025 - mean_absolute_error: 0.0379\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0024 - mean_absolute_error: 0.0379- ETA: 4s - loss: 0.0021 - mean_absolut - ETA: 1s - loss: 0.0024 - mean_absolute_error: 0.037 - ETA: 1s - loss: 0.0024 - mean_absolute_error\n",
      "Epoch 00012: loss improved from 0.00247 to 0.00244, saving model to pesos.h5\n",
      "36/36 [==============================] - 7s 206ms/step - loss: 0.0024 - mean_absolute_error: 0.0379\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0022 - mean_absolute_error: 0.0360\n",
      "Epoch 00013: loss improved from 0.00244 to 0.00218, saving model to pesos.h5\n",
      "36/36 [==============================] - 7s 195ms/step - loss: 0.0022 - mean_absolute_error: 0.0360\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0349\n",
      "Epoch 00014: loss improved from 0.00218 to 0.00210, saving model to pesos.h5\n",
      "36/36 [==============================] - 7s 195ms/step - loss: 0.0021 - mean_absolute_error: 0.0349\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0022 - mean_absolute_error: 0.0358- ETA: 3s - loss: 0.00 - ETA: 0s - loss: 0.0022 - mean_absolute_error: 0.03\n",
      "Epoch 00015: loss did not improve from 0.00210\n",
      "36/36 [==============================] - 8s 213ms/step - loss: 0.0022 - mean_absolute_error: 0.0358\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0345\n",
      "Epoch 00016: loss improved from 0.00210 to 0.00193, saving model to pesos.h5\n",
      "36/36 [==============================] - 8s 220ms/step - loss: 0.0019 - mean_absolute_error: 0.0345\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0324\n",
      "Epoch 00017: loss improved from 0.00193 to 0.00175, saving model to pesos.h5\n",
      "36/36 [==============================] - 8s 212ms/step - loss: 0.0018 - mean_absolute_error: 0.0324\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0331\n",
      "Epoch 00018: loss did not improve from 0.00175\n",
      "36/36 [==============================] - 7s 199ms/step - loss: 0.0018 - mean_absolute_error: 0.0331\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0321\n",
      "Epoch 00019: loss did not improve from 0.00175\n",
      "36/36 [==============================] - 8s 211ms/step - loss: 0.0018 - mean_absolute_error: 0.0321\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0304- ETA: 4s - loss: 0.0017 - mean_a\n",
      "Epoch 00020: loss improved from 0.00175 to 0.00161, saving model to pesos.h5\n",
      "36/36 [==============================] - 8s 212ms/step - loss: 0.0016 - mean_absolute_error: 0.0304\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0324\n",
      "Epoch 00021: loss did not improve from 0.00161\n",
      "36/36 [==============================] - 7s 199ms/step - loss: 0.0018 - mean_absolute_error: 0.0324\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0295\n",
      "Epoch 00022: loss improved from 0.00161 to 0.00153, saving model to pesos.h5\n",
      "36/36 [==============================] - 8s 214ms/step - loss: 0.0015 - mean_absolute_error: 0.0295\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0301\n",
      "Epoch 00023: loss did not improve from 0.00153\n",
      "36/36 [==============================] - 8s 210ms/step - loss: 0.0016 - mean_absolute_error: 0.0301\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0301\n",
      "Epoch 00024: loss did not improve from 0.00153\n",
      "36/36 [==============================] - 7s 207ms/step - loss: 0.0016 - mean_absolute_error: 0.0301\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0319\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00153\n",
      "36/36 [==============================] - 7s 202ms/step - loss: 0.0017 - mean_absolute_error: 0.0319\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0285\n",
      "Epoch 00026: loss improved from 0.00153 to 0.00141, saving model to pesos.h5\n",
      "36/36 [==============================] - 7s 206ms/step - loss: 0.0014 - mean_absolute_error: 0.0285\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0277- ETA: 5s - loss: 0.0013 - mean_absolute_error: 0.02 - ETA: 4s - loss: 0.0012 - \n",
      "Epoch 00027: loss improved from 0.00141 to 0.00134, saving model to pesos.h5\n",
      "36/36 [==============================] - 7s 208ms/step - loss: 0.0013 - mean_absolute_error: 0.0277\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0285- ETA: 5s - loss: 0.001\n",
      "Epoch 00028: loss did not improve from 0.00134\n",
      "36/36 [==============================] - 7s 208ms/step - loss: 0.0015 - mean_absolute_error: 0.0285\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0278\n",
      "Epoch 00029: loss did not improve from 0.00134\n",
      "36/36 [==============================] - 8s 209ms/step - loss: 0.0014 - mean_absolute_error: 0.0278\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0274\n",
      "Epoch 00030: loss improved from 0.00134 to 0.00129, saving model to pesos.h5\n",
      "36/36 [==============================] - 8s 210ms/step - loss: 0.0013 - mean_absolute_error: 0.0274\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0284\n",
      "Epoch 00031: loss did not improve from 0.00129\n",
      "36/36 [==============================] - 8s 210ms/step - loss: 0.0014 - mean_absolute_error: 0.0284\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0279- ETA: 2s - loss: 0.0013 - mean_absolute_err\n",
      "Epoch 00032: loss did not improve from 0.00129\n",
      "36/36 [==============================] - 7s 206ms/step - loss: 0.0014 - mean_absolute_error: 0.0279\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0267\n",
      "Epoch 00033: loss improved from 0.00129 to 0.00125, saving model to pesos.h5\n",
      "36/36 [==============================] - 7s 207ms/step - loss: 0.0012 - mean_absolute_error: 0.0267\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0272- ETA: 3s - loss: 0.0014 - mean_absol\n",
      "Epoch 00034: loss did not improve from 0.00125\n",
      "36/36 [==============================] - 7s 189ms/step - loss: 0.0013 - mean_absolute_error: 0.0272\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0271- ETA: 3s - loss: 0.0014 - mean_a\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00125\n",
      "36/36 [==============================] - 6s 179ms/step - loss: 0.0014 - mean_absolute_error: 0.0271\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0265\n",
      "Epoch 00036: loss did not improve from 0.00125\n",
      "36/36 [==============================] - 6s 177ms/step - loss: 0.0013 - mean_absolute_error: 0.0265\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0274\n",
      "Epoch 00037: loss did not improve from 0.00125\n",
      "36/36 [==============================] - 6s 176ms/step - loss: 0.0013 - mean_absolute_error: 0.0274\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0269\n",
      "Epoch 00038: loss did not improve from 0.00125\n",
      "36/36 [==============================] - 6s 168ms/step - loss: 0.0013 - mean_absolute_error: 0.0269\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0265\n",
      "Epoch 00039: loss improved from 0.00125 to 0.00125, saving model to pesos.h5\n",
      "36/36 [==============================] - 6s 178ms/step - loss: 0.0012 - mean_absolute_error: 0.0265\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0259\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 00040: loss improved from 0.00125 to 0.00123, saving model to pesos.h5\n",
      "36/36 [==============================] - 7s 185ms/step - loss: 0.0012 - mean_absolute_error: 0.0259\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0267\n",
      "Epoch 00041: loss did not improve from 0.00123\n",
      "36/36 [==============================] - 5s 135ms/step - loss: 0.0012 - mean_absolute_error: 0.0267\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0262\n",
      "Epoch 00042: loss improved from 0.00123 to 0.00123, saving model to pesos.h5\n",
      "36/36 [==============================] - 6s 155ms/step - loss: 0.0012 - mean_absolute_error: 0.0262\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0264\n",
      "Epoch 00043: loss did not improve from 0.00123\n",
      "36/36 [==============================] - 5s 135ms/step - loss: 0.0013 - mean_absolute_error: 0.0264\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0268\n",
      "Epoch 00044: loss did not improve from 0.00123\n",
      "36/36 [==============================] - 5s 132ms/step - loss: 0.0013 - mean_absolute_error: 0.0268\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0270\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00123\n",
      "36/36 [==============================] - 5s 137ms/step - loss: 0.0013 - mean_absolute_error: 0.0270\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0259\n",
      "Epoch 00046: loss improved from 0.00123 to 0.00119, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 137ms/step - loss: 0.0012 - mean_absolute_error: 0.0259\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0263\n",
      "Epoch 00047: loss did not improve from 0.00119\n",
      "36/36 [==============================] - 5s 134ms/step - loss: 0.0012 - mean_absolute_error: 0.0263\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0271\n",
      "Epoch 00048: loss did not improve from 0.00119\n",
      "36/36 [==============================] - 5s 135ms/step - loss: 0.0013 - mean_absolute_error: 0.0271\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0281\n",
      "Epoch 00049: loss did not improve from 0.00119\n",
      "36/36 [==============================] - 5s 135ms/step - loss: 0.0014 - mean_absolute_error: 0.0281\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0265\n",
      "Epoch 00050: loss did not improve from 0.00119\n",
      "36/36 [==============================] - 5s 132ms/step - loss: 0.0012 - mean_absolute_error: 0.0265\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0271\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 00051: loss did not improve from 0.00119\n",
      "36/36 [==============================] - 5s 136ms/step - loss: 0.0013 - mean_absolute_error: 0.0271\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0260\n",
      "Epoch 00052: loss did not improve from 0.00119\n",
      "36/36 [==============================] - 5s 138ms/step - loss: 0.0012 - mean_absolute_error: 0.0260\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0270\n",
      "Epoch 00053: loss did not improve from 0.00119\n",
      "36/36 [==============================] - 5s 136ms/step - loss: 0.0013 - mean_absolute_error: 0.0270\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0266\n",
      "Epoch 00054: loss did not improve from 0.00119\n",
      "36/36 [==============================] - 5s 137ms/step - loss: 0.0012 - mean_absolute_error: 0.0266\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0261\n",
      "Epoch 00055: loss did not improve from 0.00119\n",
      "36/36 [==============================] - 5s 135ms/step - loss: 0.0012 - mean_absolute_error: 0.0261\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0265\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "\n",
      "Epoch 00056: loss did not improve from 0.00119\n",
      "36/36 [==============================] - 5s 135ms/step - loss: 0.0012 - mean_absolute_error: 0.0265\n",
      "Epoch 00056: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "base = pd.read_csv('petr4_treinamento.csv')\n",
    "base = base.dropna()\n",
    "base_treinamento = base.iloc[:, 1:7].values\n",
    "\n",
    "normalizador = MinMaxScaler(feature_range=(0,1))\n",
    "base_treinamento_normalizada = normalizador.fit_transform(base_treinamento)\n",
    "\n",
    "normalizador_previsao = MinMaxScaler(feature_range=(0,1))\n",
    "normalizador_previsao.fit_transform(base_treinamento[:,0:1])\n",
    "\n",
    "previsores = []\n",
    "preco_real = []\n",
    "for i in range(90, 1242):\n",
    "    previsores.append(base_treinamento_normalizada[i-90:i, 0:6])\n",
    "    preco_real.append(base_treinamento_normalizada[i, 0])\n",
    "previsores, preco_real = np.array(previsores), np.array(preco_real)\n",
    "\n",
    "regressor = Sequential()\n",
    "regressor.add(LSTM(units = 100, return_sequences = True, input_shape = (previsores.shape[1], 6)))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "regressor.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error',\n",
    "                  metrics = ['mean_absolute_error'])\n",
    "\n",
    "es = EarlyStopping(monitor = 'loss', min_delta = 1e-10, patience = 10, verbose = 1)\n",
    "rlr = ReduceLROnPlateau(monitor = 'loss', factor = 0.2, patience = 5, verbose = 1)\n",
    "mcp = ModelCheckpoint(filepath = 'pesos.h5', monitor = 'loss', \n",
    "                      save_best_only = True, verbose = 1)\n",
    "regressor.fit(previsores, preco_real, epochs = 100, batch_size = 32,\n",
    "              callbacks = [es, rlr, mcp])\n",
    "\n",
    "base_teste = pd.read_csv('petr4_teste.csv')\n",
    "preco_real_teste = base_teste.iloc[:, 1:2].values\n",
    "frames = [base, base_teste]\n",
    "base_completa = pd.concat(frames)\n",
    "base_completa = base_completa.drop('Date', axis = 1)\n",
    "\n",
    "entradas = base_completa[len(base_completa) - len(base_teste) - 90:].values\n",
    "entradas = normalizador.transform(entradas)\n",
    "\n",
    "X_teste = []\n",
    "for i in range(90, 112):\n",
    "    X_teste.append(entradas[i-90:i, 0:6])\n",
    "X_teste = np.array(X_teste)\n",
    "\n",
    "previsoes = regressor.predict(X_teste)\n",
    "previsoes = normalizador_previsao.inverse_transform(previsoes)\n",
    "\n",
    "previsoes.mean()\n",
    "preco_real_teste.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(preco_real_teste, color = 'red', label = 'Preço real')\n",
    "plt.plot(previsoes, color = 'blue', label = 'Previsões')\n",
    "plt.title('Previsão preço das ações')\n",
    "plt.xlabel('Tempo')\n",
    "plt.ylabel('Valor Yahoo')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda38167b8c1ef44120b52038489a440cfb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
